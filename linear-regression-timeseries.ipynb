{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2484624,"sourceType":"datasetVersion","datasetId":1169793}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'''\nThe 'ts-course-data' dataset appears to contain information related to courses, possibly in a time series format, with columns representing the year and the availability of course materials in hardcover and paperback formats. The 'year' column likely denotes the academic year or the chronological order of data collection, while the 'hardcover' and 'paperback' columns likely indicate the availability or usage of course materials in those respective formats during each year. This dataset could be valuable for analyzing trends in course material preferences over time, evaluating the popularity of different formats, or understanding shifts in educational resources within a specific academic context.\n'''","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import  LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\nplt.rcParams['figure.figsize']=[8,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reading the csv file","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/ts-course-data/book_sales.csv')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'''\n'hardcover' column already provides sufficient information about the availability or usage of course materials in physical format, keeping both columns might lead to redundancy and unnecessary duplication of data.\n'''","metadata":{}},{"cell_type":"code","source":"# dropping the paperback column\ndf.drop(['Paperback'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'''\nSetting the index of your DataFrame to the 'Date' column is a crucial step for time series modeling. This ensures that your data is organized chronologically, which is essential for analyzing and forecasting time-dependent patterns. By setting the index to the date, you enable efficient time-based operations such as resampling, slicing, and lagging, which are fundamental in time series analysis.\n'''","metadata":{}},{"cell_type":"code","source":"df.set_index('Date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'''\nAdding a time variable to your dataframe is a crucial step for time series modeling. This allows you to incorporate the temporal aspect into your analysis, enabling your model to understand and leverage patterns over time. With the 'Time' variable representing the sequence of observations, your model can better capture trends, seasonality, and other time-dependent patterns. It's a fundamental component for building accurate and robust time series models.\n'''","metadata":{}},{"cell_type":"code","source":"'''\ny(hardware)=w*(time)+b\n'''\n\ndf['Time']=np.arange(len(df.index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'''\nLag features are essentially creating new columns in a DataFrame by shifting existing columns by a certain number of time steps. These lag features are useful in time series analysis and forecasting tasks as they capture past values of a variable which can be predictive of future values.\n'''","metadata":{}},{"cell_type":"code","source":"'''\nLag Features = Extra feature column\n'''\ndf['Lag1']=df['Hardcover'].shift(1)\ndf['Lag2']=df['Hardcover'].shift(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a scatter plot with a regression line using regplot\n\nsns.regplot(x='Time',y='Hardcover',data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ny(hardcover)=w*time+b\n\ny(hardcover)=w1*time+w2*previous_day_sales+w3*previous_day_sales\n'''\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill missing values with zero\ndf=df.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# partioning the data set into training and testing sets\ndf_train=df.iloc[:20]\ndf_test=df.iloc[20:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separating feature and target variable\nX_train=df_train.loc[:,['Time','Lag1','Lag2']]\ny_train=df_train.loc[:,['Hardcover']]\n\nX_test=df_test.loc[:,['Time','Lag1','Lag2']]\ny_test=df_test.loc[:,['Hardcover']]\n\nX_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#normalization\n\nss=StandardScaler() \n\n'''\nfit:mean,standard_deviation(fit)\ntransform: x-mean/standard_deviation\n'''\n\nX_train=ss.fit_transform(X_train)\nX_test=ss.fit_transform(X_test)\n\ny_train=ss.fit_transform(y_train)\ny_test=ss.fit_transform(y_test)\n\nX_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model training using training set\nlin_reg=LinearRegression()\nlin_reg.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the target variable using linear regression model on test dataset\ny_pred=lin_reg.predict(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters of the model\nlin_reg.intercept_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin_reg.coef_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating the mean square error\nmean_squared_error(y_pred,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin_reg.predict([[22, 222, 217]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Computing R-square score\nlin_reg.score(X_test,y_test)\n\n'''\nr2 score becomes negative there is no proper relation ship b/w data the model\nobtained is not good\n\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}